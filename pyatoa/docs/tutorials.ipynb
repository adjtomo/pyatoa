{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 1: core classes; general workflow\n",
    "Here we provide a brief introduction on how `Pyatoa` is intended to be used standalone.  \n",
    "`Pyatoa` is normally very quiet to avoid unnecessary outputs, however it really babbles on about everything.  \n",
    "We can use the `logging` module to see what's going on under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import obspy\n",
    "import pyatoa\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(\"pyatoa\")\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pyatoa.Config()\n",
    "`Pyatoa` is centralized around a `Config` object which controls all the parameters deemed necessary in the misfit quantification workflow. The `Config` object supports print statements to tell the User what parameters are available, and how they are set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = pyatoa.Config()\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that we have some default parameters set, e.g. the filter bands `min_period` and `max_period`, as well as configurations for the `pyflex_map` which specifies the parameters of the `pyflex_config`. We also can set the `adj_src_type` which controls the parameters of the `pyadjoint_config`. For now we will ignore the rest of the parameters and move onto the `Manager` class. \n",
    "\n",
    "### pyatoa.Manager()\n",
    "The `Manager` class always requires a `Config` input parameter. Printing the `Manager` shows us the `Pyatoa` data and workflow status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt = pyatoa.Manager(cfg)\n",
    "print(mgmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that we have no data collected and our workflow is incomplete. Although `Pyatoa` comes with data gathering capabilities, for this example we will just read in some test data. We will see that once we set the data in the Manager class, the print statement updates to show us how many Traces we have in our Streams, and the name of the station in our inventory object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt.inv = obspy.read_inventory(\"../tests/data/test_inv.xml\")\n",
    "mgmt.st_obs = obspy.read(\"../tests/data/test_obs_data.ascii\")\n",
    "mgmt.st_syn = obspy.read(\"../tests/data/test_syn_m00_data.ascii\")\n",
    "print(f\"OBSSERVED DATA\\n\\tsampling_rate:{mgmt.st_obs[0].stats.sampling_rate}, npts:{mgmt.st_obs[0].stats.npts}\\n\")\n",
    "print(f\"SYNTHETIC DATA\\n\\tsampling_rate:{mgmt.st_syn[0].stats.sampling_rate}, npts:{mgmt.st_syn[0].stats.npts}\\n\")\n",
    "print(mgmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the minimum data required to begin the workflow. However, we cannot create misfit windows or measure misfit yet, because our traces have different sampling rates, start and end-times, and spectral content. If we try to run the window() and measure() functions, we will be met with some check-stops telling us that we must first run other functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt.window()\n",
    "mgmt.measure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing\n",
    "\n",
    "The first step after gathering data is to standardize Streams. standardize() will resample and trim the data so that sampling rate, number of points, and start and end times are the same between the Observed and Synthetic traces. Data by default should conform to Synthetics, due to the requirements of a solver to receive inputs in the same manner as its outputs, but running `mgmt.standardize(standardize_to='obs')` allows the User to override this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt.standardize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mgmt.st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that after performing standardization and preprocessing, 3 of the workflow flags have been set `True`, which means we can move onto the the window() and measure() functions. Standardization and preprocessing are done in place, which means the original data is not retrievable. Accessing `mgmt.st_obs` returns the processed data.\n",
    "\n",
    "### Misfit Quantification\n",
    "\n",
    "Now that the data has been processed, we can run our misfit quantification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt.window()\n",
    "mgmt.measure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pyatoa` has run `Pyflex` and recovered 1 window for the traces, which is saved into the Manager as a dictionary. It has then run `Pyadjoint` to measure the misfit on the recovered windows from `Pyflex`. We can take a look at the `windows` and `adj_srcs` to see that they are saved as dictionaries following the `Config.component_list`. Each entry of the `windows` dictionary is a list of `Window` objects from `Pyflex`. Each entry of the `adj_srcs` is an AdjointSource object from `Pyadjoint`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Windows:\\n{mgmt.windows}\\n\")\n",
    "print(f\"Adjoint Sources:\\n{mgmt.adj_srcs}\\n\")\n",
    "print(f\"Adjoint Source Object:\\n{mgmt.adj_srcs['E']}\\n\")\n",
    "print(f\"Adjoint Source Data:\\n{mgmt.adj_srcs['E'].adjoint_source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting, mapping\n",
    "\n",
    "Plot functionalities will plot the available streams in the Manager class. If windows and adjoint sources are available for a given component, they will also be plotted alongside the waveform data. Kwargs can be passed to the plot function to change the default look of the waveform plots. Information about the chosen misfit windows, such as the time shift between Observed and Synthetic traces, will be annotated into each window.\n",
    "\n",
    "Mapping capabilities are also available. The mapping function will try to include as much information as possible. In this case since we have not included an Event in our Manager class, the mapper will only be able to plot the station. Additionally, as we have not specified any map corners, the Map will be plotted for the whole Earth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 2: custom configs for Pyflex and Pyadjoint\n",
    "Config objects are written for both [Pyflex](https://krischer.github.io/pyflex/_modules/pyflex/config.html) and [Pyadjoint](https://github.com/krischer/pyadjoint/blob/master/src/pyadjoint/config.py) so that the User could fine tune their misfit measurement criteria. For simplicitiy, these Config classes have been wrapped into the Pyatoa Config class, either through map names or key word arguments. We can take a look at the default settings by printing the Config class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "cfg = pyatoa.Config()\n",
    "print(f\"Pyflex Config Map: {cfg.pyflex_map}\")\n",
    "pprint(vars(cfg.pyflex_config))\n",
    "\n",
    "print('\\n')\n",
    "print(f\"Pyadjoint Config: {cfg.adj_src_type}\")\n",
    "pprint(vars(cfg.pyadjoint_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyflex Config\n",
    "To override the default parameters of the Pyflex Config, two options are given. \n",
    "\n",
    "1) hardcode the source-code of Pyatoa to include a preset Config map in pyatoa/plugins/pyflex_config.set_pyflex_config(). There we have already set three pre-set maps, \"example\", \"alaska\" and \"hikurangi\". Users may define their own custom choices and map names. \n",
    "\n",
    "2) pass keyword arguments through the Pyatoa Config. These are then passed to the Pyflex Config if matching attributes are found. \n",
    "\n",
    "Below we show examples of both types of overwriting. For simplicity we just look at the Pyflex Config parameter `c_0` to see how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = pyatoa.Config()\n",
    "print(f'Default c_0: {cfg.pyflex_config.c_0}')\n",
    "cfg = pyatoa.Config(pyflex_map=\"incorrect_map_names_will_set_the_pyflex_config_to_default\")\n",
    "print(f'Incorrect map name, no kwargs c_0: {cfg.pyflex_config.c_0}')\n",
    "cfg = pyatoa.Config(pyflex_map=\"hikurangi\")\n",
    "print(f'Option 1, preset map c_0: {cfg.pyflex_config.c_0}')\n",
    "cfg = pyatoa.Config(pyflex_map=None, c_0=2.0)\n",
    "print(f'Option 2, kwargs c_0: {cfg.pyflex_config.c_0}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyadjoint Config\n",
    "To overwrite the default Config parameters of pyadjoint, kwargs may be passed through the Pyatoa `Config` class to overwrite the default Pyadjoint Config parameters. Here we show examples for the `phase_step` parameter in the \n",
    "pyadjoint.Config() class. \n",
    "\n",
    "Note: Adjoint source types must also be passed to the Config parameter. Pyadjoint allows custom adjoint source types, so there are no checks for correctly specified `adj_src_type`. Attempting to run Manager.measure() with an undefined `adj_src_type` will lead to errors from Pyadjoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = pyatoa.Config()\n",
    "print(f'Default adj_src_type: {cfg.adj_src_type}')\n",
    "cfg = pyatoa.Config(adj_src_type=\"custom_adj_src_type\")\n",
    "print(f'Custom adj_src_type: {cfg.adj_src_type}')\n",
    "print(f'Default phase_step: {cfg.pyadjoint_config.phase_step}')\n",
    "cfg = pyatoa.Config(phase_step=3)\n",
    "print(f'Kwargs phase_step: {cfg.pyadjoint_config.phase_step}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutoral 3: dynamic data gathering\n",
    "\n",
    "Pyatoa allows for dynamic data gathering based on its mid-level `Gatherer` class which calls on the low-level `Getter` and `Fetcher` classes. These are all wrapped up in the `Manager` class so that the User does not need to interact with the lower levels. \n",
    "\n",
    "When data gathering, `Manager` always seeks the path of least resistance; that is, the `Manager` will always search for data internally (either via a given Pyasdf Dataset, or through directory structures), before moving on to more costly external searches which use FDSN to query webservices. We can see an example of this in the following code.\n",
    "\n",
    "Note: Data is fetched based on event origintime information. \n",
    "\n",
    "##### Internal Fetching\n",
    "\n",
    "To get the `Manager` to search internal pathways, paths must be given in the proper format.\n",
    "1) Observed data must be saved based on SEED observatory convention, that is in a specific directory structure with specific file naming, following the format:\n",
    "\n",
    "`/path/to/waveforms/YEAR/NETWORK/STATION/CHANNEL/NN.SSS.LL.CCC.D.YYYY.DDD`  \n",
    "for example  \n",
    "`/path/to/waveforms/2018/NZ/BFZ/HHZ.D/NZ.BFZ.10.HHZ.D.2018.049`\n",
    "\n",
    "2) Synthetic data should be placed in a directory, with the convention  \n",
    "`path/to/synthetics/NN.SSS.CCC.sem?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pyatoa import Config, Manager\n",
    "\n",
    "logger = logging.getLogger(\"pyatoa\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "cfg = Config(event_id=\"2018p130600\",\n",
    "             cfgpaths={\"waveforms\":\"../tests/data/test_directories/waveforms\",\n",
    "                       \"synthetics\":\"../tests/data/test_directories/synthetics\"}\n",
    "            )\n",
    "mgmt = Manager(cfg)\n",
    "mgmt.gather(station_code=\"NZ.BFZ.??.HH?\", choice=[\"st_obs\", \"st_syn\"])\n",
    "print(mgmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### External Getting\n",
    "\n",
    "We can see that we have collected data from the given directories. Since data gathering happens using event origin times, the Event must be gathered before the data. If no paths are given in the `Config.cfgpaths` parameter, and no pyasdf.ASDFDataSet is assigned to the `Manager`, then the Gatherer will query the FDSN webservice in order to download data. This has been tested with New Zealand's GeoNet FDSN client, and IRIS' FDSN client, however not with other webservices, although no problems are expected. \n",
    "\n",
    "##### Moment Tensors\n",
    "\n",
    "The Gatherer will also try to fetch moment tensor information. So far this only works for GeoNet and IRIS events. For GeoNet events, the github repository containing John Ristau's moment tensors will be read in and appended. For IRIS events, GCMT will be queried for moment tensor information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt = Manager(Config(event_id=\"2018p130600\", client=\"GEONET\"))\n",
    "mgmt.gather('NZ.BFZ.??.HH?', choice=[\"inv\", \"st_obs\"])\n",
    "print(mgmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. we can look at the 2018-01-23 Mww7.9 Gulf Of Alaska event,\n",
    "# recorded at the Black Forest Observatory in Germany\n",
    "mgmt = Manager(pyatoa.Config(event_id=\"10607586\", client=\"IRIS\"))\n",
    "mgmt.gather(\"II.ERM.00.BHZ\")\n",
    "print(mgmt)\n",
    "mgmt.st_obs.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 4: interacting with pyasdf\n",
    "\n",
    "Pyasdf datasets are HDF5 datasets that allow for heirarchical storage of seismic data. It provides a very clean and compact way to store all the data that is collected during this workflow, including raw seismic waveforms, event and response information, misfit window and adjoint source information. To enable saving to a Pyasdf Dataset, you simply need to set your target dataset as an input when calling the `Manager` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyasdf\n",
    "import logging\n",
    "from pyatoa import Config, Manager\n",
    "\n",
    "logger = logging.getLogger(\"pyatoa\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "ds = pyasdf.ASDFDataSet(\"test_dataset.h5\")\n",
    "\n",
    "cfg = Config(event_id=\"2018p130600\", client=\"GEONET\", \n",
    "             cfgpaths={\"synthetics\":\"../tests/data/test_directories/synthetics\",\n",
    "                       \"waveforms\":\"../tests/data/test_directories/waveforms\"}\n",
    "             )\n",
    "cfg.write(write_to=ds)\n",
    "mgmt = Manager(cfg, ds=ds)\n",
    "mgmt.gather(\"NZ.BFZ.??.HH?\")\n",
    "print(mgmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"DATASET:\\n{ds}\\n\\n\"\n",
    "      f\"EVENTS:\\n{ds.events}\\n\\n\"\n",
    "      f\"STATION:\\n{ds.waveforms['NZ.BFZ']}\\n\\n\"\n",
    "      f\"INVENTORY:\\n{ds.waveforms['NZ.BFZ'].StationXML}\\n\\n\"\n",
    "      f\"WAVEFORMS:\\n{ds.waveforms['NZ.BFZ']['observed']}\"\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt.standardize()\n",
    "mgmt.preprocess()\n",
    "mgmt.window()\n",
    "mgmt.measure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"AUX DATA:\\n{ds.auxiliary_data}\\n\\n\"\n",
    "      f\"WINDOWS:\\n{ds.auxiliary_data.MisfitWindows['None'].NZ_BFZ_E_0}\\n\\n\"\n",
    "      f\"ADJOINT SOURCES:\\n{ds.auxiliary_data.AdjointSources['None'].NZ_BFZ_HXE}\"\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 6: visualization\n",
    "\n",
    "To be written"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 7: export to Specfem3D\n",
    "\n",
    "To be written"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 8: plugin to Seisflows\n",
    "\n",
    "To be written"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 9: misfit statistics\n",
    "\n",
    "To be written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
